from google.colab import files
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

uploaded = files.upload()
!pip install gradio
import gradio as gr
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

def preprocess_data(df):
    # Combine Date & Time to datetime, if Time exists
    if 'Date' in df.columns and 'Time' in df.columns:
        df['Datetime'] = pd.to_datetime(df['Date'] + ' ' + df['Time'])
        df = df.sort_values('Datetime')
    elif 'Date' in df.columns:
        df['Datetime'] = pd.to_datetime(df['Date'])
        df = df.sort_values('Datetime')
    else:
        raise ValueError("CSV must contain 'Date' column (and optionally 'Time').")
    
    # Select features for modeling
    required_cols = ['Open', 'High', 'Low', 'Close', 'Volume']
    for col in required_cols:
        if col not in df.columns:
            raise ValueError(f"CSV must contain '{col}' column.")
    
    features = df[required_cols].values
    return features, df['Datetime']

def create_dataset_multivariate(data, time_step=10):
    X, Y = [], []
    for i in range(len(data)-time_step):
        X.append(data[i:(i+time_step), :])  # all features
        Y.append(data[i+time_step, 3])      # Close price is at index 3
    return np.array(X), np.array(Y)

def train_and_predict(file, time_step=10, epochs=20):
    df = pd.read_csv(file.name)
    try:
        data, dates = preprocess_data(df)
    except Exception as e:
        return f"Error processing data: {e}", None
    
    scaler = MinMaxScaler()
    scaled_data = scaler.fit_transform(data)
    
    X, Y = create_dataset_multivariate(scaled_data, time_step)
    if len(X) == 0:
        return "Not enough data for the chosen time_step. Try reducing it.", None
    
    # Reshape for LSTM input: [samples, time_steps, features]
    X = X.reshape(X.shape[0], X.shape[1], X.shape[2])
    
    model = Sequential()
    model.add(LSTM(50, return_sequences=True, input_shape=(time_step, X.shape[2])))
    model.add(LSTM(50))
    model.add(Dense(1))
    model.compile(loss='mean_squared_error', optimizer='adam')
    
    model.fit(X, Y, epochs=epochs, batch_size=32, verbose=0)
    
    # Predict on training data
    train_predict = model.predict(X)
    
    # Inverse scale predictions and actual close prices
    close_idx = 3
    # We only inverse transform Close price - trick: create empty array and put predictions there
    dummy_pred = np.zeros((len(train_predict), data.shape[1]))
    dummy_actual = np.zeros((len(Y), data.shape[1]))
    dummy_pred[:, close_idx] = train_predict[:, 0]
    dummy_actual[:, close_idx] = Y
    
    inv_pred = scaler.inverse_transform(dummy_pred)[:, close_idx]
    inv_actual = scaler.inverse_transform(dummy_actual)[:, close_idx]
    
    # Plot actual vs predicted Close price
    plt.figure(figsize=(10,6))
    plt.plot(inv_actual, label='Actual Close Price')
    plt.plot(inv_pred, label='Predicted Close Price')
    plt.title('Stock Close Price Prediction')
    plt.xlabel('Time Steps')
    plt.ylabel('Price')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig("plot.png")
    plt.close()
    
    return "Model trained successfully!", "plot.png"

iface = gr.Interface(
    fn=train_and_predict,
    inputs=[
        gr.File(label="Upload CSV file with columns: Date, Time (optional), Open, High, Low, Close, Volume"),
        gr.Slider(1, 30, value=10, step=1, label="Time Step (sequence length)"),
        gr.Slider(1, 100, value=20, step=1, label="Epochs"),
    ],
    outputs=[
        gr.Textbox(label="Status"),
        gr.Image(type="filepath", label="Actual vs Predicted Close Price Plot")
    ],
    title="Multivariate Stock Price Prediction with LSTM",
    description="Upload a CSV with your stock data. The model uses Open, High, Low, Close, and Volume features to predict the Close price."
)

iface.launch()
